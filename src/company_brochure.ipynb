{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "637af3cd-4fa1-4f7d-bc03-946781fdd106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee198818-1545-407c-b7ee-c196aac710a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize and constants\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "MODEL = 'gpt-4o-mini'\n",
    "OLLAMA_MODEL = 'qwen2.5'\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1eda562d-2a56-4f84-a3c1-dbd076a2f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped, with links\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get('href') for link in soup.find_all('a')] \n",
    "        self.links = [link for link in links if link] \n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b638676c-48e0-4c3e-9e32-fc4af510c6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Have GPT-4o-mini to extract relevant links from our list of links\n",
    "# Apply one-shot prompting.\n",
    "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
    "link_system_prompt += \"You should respond in JSON as in this example:\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt\n",
    "def get_links(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create( \n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "      ],\n",
    "        response_format={\"type\": \"json_object\"} \n",
    "    )\n",
    "    result = response.choices[0].message.content \n",
    "    return json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b52ef13-8c0c-4468-8882-fc6dfbe62839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create a Brochure out of all scraped links\n",
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\"\n",
    "def gather_details(url):\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()\n",
    "    links = get_links(url)\n",
    "    for link in links[\"links\"]:\n",
    "        result += f\"\\n\\n{link['type']}\\n\"\n",
    "        result += Website(link[\"url\"]).get_contents()\n",
    "    return result\n",
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += gather_details(url)\n",
    "    user_prompt = user_prompt[:20_000] # Truncate if more than 20,000 characters\n",
    "    return user_prompt\n",
    "def create_brochure(company_name, url):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f3c92a4-7ab7-41c3-a088-41615ab6c7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest â ‹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ™ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ´ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â § \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 2bada8a74506... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 4.7 GB                         \n",
      "pulling 66b9ea09bd5b... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�   68 B                         \n",
      "pulling eb4402837c78... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.5 KB                         \n",
      "pulling 832dd9e00a68... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  11 KB                         \n",
      "pulling 2f15b3218f05... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  487 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "# Model from Alibaba which is (suppsed to be) good at diverse languages\n",
    "# Making sure you have downloaded this model\n",
    "!ollama pull qwen2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b70861a4-cd48-4cb8-80bd-2d0fd66ddc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Use Local Ollama Model (qwen2.5) for Translation - Testing But not Recommended as Qwen 2.5 is somewhat not that fluent\n",
    "translate_system_prompt = 'You are an assistant that translates a company brochure that is in English and given in Markdown format.\\\n",
    " Translate the brochure to the language that is given in the user prompt. Respond in Markdown.'\n",
    "    \n",
    "def translate_brochure(company_name, url, language):\n",
    "    brochure_content = create_brochure(company_name, url)\n",
    "    if language == \"English\":\n",
    "        return brochure_content\n",
    "    user_prompt = f'Translate the given brochure content to {language}.\\n\\nBrochure Content: {brochure_content}.'\n",
    "    messages = [{'role':'system', 'content':translate_system_prompt},\n",
    "               {'role':'user', 'content': user_prompt}]\n",
    "    response = ollama.chat(model=OLLAMA_MODEL, messages=messages)\n",
    "    return (response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4656dd2f-84dd-4ec4-9ac0-eecac0f79844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Simple User Interface with Gradio (HuggingFace's)\n",
    "languages = ['Chinese', 'English', 'French', 'Spanish', 'Portugese', 'German', 'Italian', 'Russian', 'Japanese', 'Korean', 'Vietnamese', 'Thai', 'Arabic']\n",
    "view = gr.Interface(\n",
    "    fn=translate_brochure,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Company name:\"),\n",
    "        gr.Textbox(label=\"Landing page URL including http:// or https://\"),\n",
    "        gr.Dropdown(label='Supported Languages (English is Highly Preferred):', choices = languages, value='English')],\n",
    "    outputs=[gr.Markdown(label=\"Brochure:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7682cf5a-8d60-4927-9c7e-79beda039c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
